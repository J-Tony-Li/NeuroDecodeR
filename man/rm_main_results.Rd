% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rm_main_results.R
\name{rm_main_results}
\alias{rm_main_results}
\title{A result metric (RM) that calculates main decoding accuracy measures}
\usage{
rm_main_results(
  aggregate_decision_values = TRUE,
  aggregate_normalized_rank = TRUE
)
}
\arguments{
\item{aggregate_decision_values}{A string or boolean specifying how the
decision values should be aggregated. If this is a boolean
set to TRUE or to the string "full", then the decision values for the correct
category will be calculated. If this is a boolean set to FALSE or to the
string "none", then the decision values will not be calculated. If this is a
string set to either "diag" or "only same train test time" then the decision
values will only be calculated when for results when training and testing
at the same time. Not returning the full results can speed up the runtime
of the code and will use less memory so this can be useful for large data sets.}

\item{aggregate_normalized_rank}{A string or boolean specifying how the
normalized rank results should be aggregated. If this is a boolean
set to TRUE or to the string "full", then the decision values for the correct
category will be calculated. If this is a boolean set to FALSE or to the
string "none", then the decision values will not be calculated. If this is a
string set to either "diag" or "only same train test time" then the decision
values will only be calculated when for results when training and testing
at the same time. Not returning the full results can grealy speed up the runtime
of the code and will use less memory so this can be useful for large data sets.}
}
\description{
This result metric calculate the zero-one loss, the normalized rank, and the
mean of the decision values. This is also an S3 object which has an associated
plot function to display the results.
}
\details{
Like all result metrics, this result metric has functions to aggregregate
results after completing each set of cross-validation classifications, and
also after completing all the resample runs. The results should then be
available in the DECODING_RESULTS object returned by the cross-validator.
}
\examples{
# This result metric does not take any arguments.
# If you only want to use the rm_main_results(), then you can put it in a
# list by itself and pass it to the cross-validator.
the_rms <- list(rm_main_results())

}
\seealso{
Other result_metrics: 
\code{\link{plot.rm_confusion_matrix}()},
\code{\link{plot.rm_main_results}()},
\code{\link{plot_MI.rm_confusion_matrix}()},
\code{\link{rm_confusion_matrix}()}
}
\concept{result_metrics}
